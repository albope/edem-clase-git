{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Performance Improvement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albope/master-data-analytics-content/blob/master/CNN_Performance_Improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL8RQZGoqqQJ",
        "colab_type": "text"
      },
      "source": [
        "# Workshop 3: CNN state of the art\n",
        "\n",
        "In this workshop we will learn techniques to increase the performance of CNN and how to use state of the art architectures. The structure of the workshop will be the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   Dropout\n",
        "2.   Batch Normalization\n",
        "3.   Data Augmentation\n",
        "4.   Transfer learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y91AuX2jrJDo",
        "colab_type": "text"
      },
      "source": [
        "## 1. Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxUYGXkFPG98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependence for downloading CIFAR10\n",
        "from keras.datasets import cifar10 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGDZgZkS9c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_testval, y_testval) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA-qauKITM-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependence for handling arrays\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ5vh3g8Xh_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the range of pixels from [0 255] to [0 1]\n",
        "X_train_fl = X_train.astype('float32')\n",
        "X_testval_fl = X_testval.astype('float32')\n",
        "X_train_fl /= 255\n",
        "X_testval_fl /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj74QnR4Vbt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependence for one-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nTRJ7yeVeN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding of labels\n",
        "onehot_enc = OneHotEncoder()\n",
        "y_train_oh = onehot_enc.fit_transform(y_train.reshape(X_train.shape[0], 1)).toarray()\n",
        "y_testval_oh = onehot_enc.fit_transform(y_testval.reshape(X_testval.shape[0], 1)).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry7H5BvPVl6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show one-hot encoded labels shape\n",
        "print(\"Training one-hot encoded labels shape:\", y_train_oh.shape)\n",
        "print(\"Testing one-hot encoded labels shape:\", y_testval_oh.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PoZUM_sVoi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divide testval in test and validation partitions\n",
        "samples_test_nb = int(X_testval.shape[0]/2)\n",
        "X_val = X_testval_fl[:samples_test_nb]\n",
        "y_val = y_testval_oh[:samples_test_nb]\n",
        "X_test = X_testval_fl[samples_test_nb:]\n",
        "y_test = y_testval_oh[samples_test_nb:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgM7brWVsN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show shapes of test and validation partitions\n",
        "print(\"Validation matrix shape:\", X_val.shape)\n",
        "print(\"Testing matrix shape:\", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo5FvhBYubiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import depence for CNN\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrbz0cUmtuU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "input_layer = Input(shape=(X_train.shape[1],X_train.shape[2], X_train.shape[3]))\n",
        "conv_layer_1 = Conv2D(filters=8, kernel_size=(3, 3), activation='relu')(input_layer)\n",
        "maxpool_layer_1 = MaxPool2D(pool_size=(2, 2))(conv_layer_1)\n",
        "conv_layer_2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(maxpool_layer_1)\n",
        "maxpool_layer_2 = MaxPool2D(pool_size=(2, 2))(conv_layer_2)\n",
        "conv_layer_3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(maxpool_layer_2)\n",
        "flatten_layer = Flatten()(conv_layer_3)\n",
        "dense_layer = Dense(128, activation='relu')(flatten_layer)\n",
        "dropout = Dropout(rate=0.4)(dense_layer)\n",
        "output_layer = Dense(10, activation='softmax')(dropout)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzt4Th7iV1tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show a summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFM5py6aV4DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a6viyT4V_9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_fl, y_train_oh, epochs=50, batch_size=128,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsc8-QX1xVWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependence for visualization of images\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAR15yICV6hU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "# plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OM3GB9SV86n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training and test loss\n",
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Model loss') \n",
        "plt.ylabel('Loss') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'Val'], loc='upper left') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1huEX1wx5bn",
        "colab_type": "text"
      },
      "source": [
        "## 2. Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEFeuHMNvQxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZfVtoxky-8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "input_layer = Input(shape=(X_train.shape[1],X_train.shape[2], X_train.shape[3]))\n",
        "conv_layer_1 = Conv2D(filters=8, kernel_size=(3, 3), activation='relu')(input_layer)\n",
        "bn_1 = BatchNormalization()(conv_layer_1)\n",
        "maxpool_layer_1 = MaxPool2D(pool_size=(2, 2))(bn_1)\n",
        "conv_layer_2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(maxpool_layer_1)\n",
        "bn_2 = BatchNormalization()(conv_layer_2)\n",
        "maxpool_layer_2 = MaxPool2D(pool_size=(2, 2))(bn_2)\n",
        "conv_layer_3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(maxpool_layer_2)\n",
        "bn_3 = BatchNormalization()(conv_layer_3)\n",
        "flatten_layer = Flatten()(bn_3)\n",
        "dense_layer = Dense(128, activation='relu')(flatten_layer)\n",
        "dropout = Dropout(rate=0.4)(dense_layer)\n",
        "output_layer = Dense(10, activation='softmax')(dropout)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jG1aPlHFze4L",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UIJo6a5kze4P",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_fl, y_train_oh, epochs=20, batch_size=128,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efPQki1pzZ9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with new learning rate\n",
        "model= Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo6f1rlo0qWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_fl, y_train_oh, epochs=20, batch_size=128,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsfjI7S2eCH",
        "colab_type": "text"
      },
      "source": [
        "## 3. Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGqUrVUa063z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjoPmQc32nmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define data generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 10,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeXelmgq6IkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert a categorical class to its corresponding string\n",
        "def class_to_string(class_int):\n",
        "    classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\n",
        "               \"horse\", \"ship\", \"truck\"]\n",
        "    return classes[class_int]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgMWPtwx6fTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (10,10)  # Configure figure size for \n",
        "                                          # appropriate visualization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gp_wWxK3xc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show generated data\n",
        "iterator = train_datagen.flow(X_train_fl, y_train_oh, batch_size=9)\n",
        "samples, labels = next(iterator)\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(samples[i], interpolation='none')\n",
        "    class_str = class_to_string(np.argmax(labels[i]))\n",
        "    plt.title(\"Class: \" + class_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kj3tqJnv74Yn",
        "colab": {}
      },
      "source": [
        "# Compile the model with new learning rate\n",
        "model= Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dW6z6oqi74Yu",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "batch_size = 100\n",
        "steps_per_epoch = X_train.shape[0] / batch_size\n",
        "history = model.fit_generator(train_datagen.flow(X_train_fl, y_train_oh, \n",
        "                                                 batch_size=batch_size), \n",
        "                              epochs=20,\n",
        "                              steps_per_epoch=steps_per_epoch, \n",
        "                              validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGTb98saDb6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "batch_size = 100\n",
        "steps_per_epoch = X_train.shape[0] / batch_size\n",
        "history = model.fit_generator(train_datagen.flow(X_train_fl, y_train_oh, \n",
        "                                                 batch_size=batch_size), \n",
        "                              epochs=100,\n",
        "                              steps_per_epoch=steps_per_epoch, \n",
        "                              validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBnVN5aoL_MJ",
        "colab_type": "text"
      },
      "source": [
        "## 4. Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaqBTy80-PfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dependences for transfer learning\n",
        "from keras.applications import ResNet50\n",
        "from keras.models import Sequential\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoz0Dt6SV3QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, \n",
        "                        input_shape=(256, 256, 3))\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D((2,2)))\n",
        "model.add(UpSampling2D((2,2)))\n",
        "model.add(UpSampling2D((2,2)))\n",
        "model.add(resnet_model)\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arWFKw9yZF9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=RMSprop(lr=2e-5), loss='categorical_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4zR1iAiZQbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_fl, y_train_oh, epochs=5, batch_size=50, \n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp2NFx0MiXPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "batch_size = 20\n",
        "steps_per_epoch = X_train.shape[0] / batch_size\n",
        "history = model.fit_generator(train_datagen.flow(X_train_fl, y_train_oh, \n",
        "                                                 batch_size=batch_size), \n",
        "                              epochs=5,\n",
        "                              steps_per_epoch=steps_per_epoch, \n",
        "                              validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
